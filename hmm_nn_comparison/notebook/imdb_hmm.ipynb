{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4050c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 11:31:55.120002: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-04 11:31:55.120017: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from hmmlearn import hmm\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f678d31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 9s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# load database using keras: the most frequent 10000 words\n",
    "(train_data, train_labels), \\\n",
    "(test_data, test_labels) = imdb.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6200d422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum word index (training data): 9999\n",
      "Minimum word index (training data): 1\n",
      "Maximum seq length (training data): 2494\n",
      "Minimum seq length (training data): 11\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum of all max indexes\n",
    "max_word_index = max([max(sequence) for sequence in train_data])\n",
    "min_word_index = min([min(sequence) for sequence in train_data])\n",
    "max_seq_len = max([len(sequence) for sequence in train_data])\n",
    "min_seq_len = min([len(sequence) for sequence in train_data])\n",
    "print(f'Maximum word index (training data): {max_word_index}')\n",
    "print(f'Minimum word index (training data): {min_word_index}')\n",
    "print(f'Maximum seq length (training data): {max_seq_len}')\n",
    "print(f'Minimum seq length (training data): {min_seq_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47cedd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1641221/1641221 [==============================] - 1s 0us/step\n",
      "REVIEW:\n",
      " ? the true measure of any fictional piece of work is whether or not the characters grow from their experiences and emerge from the experience altered in some significant way note that this change need not be positive or ? at the end br br by that measure enchanted april is a ? success as a film in general it succeeds quite well excellent ensemble cast well developed characters you come to care about wonderful script and beautiful sets and locations in short the film is well enchanting although all the performances are first rate three must be mentioned ? lawrence jim ? and joan ? it says something when miranda richardson does her usual fine work and yet is overshadowed by so many others in the cast most highly recommended particularly if you are a romantic at heart further ? ? not\n",
      "\n",
      "Encoded sequence of words:\n",
      " [1, 4, 283, 4160, 7, 101, 2615, 418, 7, 157, 9, 726, 42, 24, 4, 105, 2306, 39, 68, 2490, 5, 6050, 39, 4, 585, 6052, 11, 49, 2681, 96, 854, 15, 14, 653, 359, 24, 30, 1123, 42, 2, 33, 4, 130, 10, 10, 34, 15, 4160, 7372, 4324, 9, 6, 2, 1023, 17, 6, 22, 11, 831, 12, 2880, 179, 73, 321, 3137, 177, 73, 1391, 105, 25, 216, 8, 459, 44, 389, 229, 5, 307, 732, 5, 1979, 11, 346, 4, 22, 9, 73, 7506, 261, 32, 4, 354, 26, 86, 967, 289, 215, 30, 1046, 2, 4243, 1240, 2, 5, 1820, 2, 12, 560, 142, 54, 6689, 4798, 127, 41, 644, 478, 157, 5, 246, 9, 8326, 34, 38, 111, 409, 11, 4, 177, 91, 545, 1178, 572, 48, 25, 26, 6, 731, 33, 483, 1037, 2, 2, 24]\n",
      "\n",
      "Label: positive review\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# step 1 : get word index\n",
    "word_index = imdb.get_word_index()\n",
    "ind = random.randint(0,len(train_data))\n",
    "\n",
    "# step 2: reverse word index to map integer indexes to their respective words\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# Step 3: decode the review, mapping integer indices to words\n",
    "#\n",
    "# indices are off by 3 because 0, 1, and 2 are reserverd indices for \"padding\", \"Start of sequence\" and \"unknown\"\n",
    "decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[ind]])\n",
    "label = 'positive review' if train_labels[ind] == 1 else 'negative review'\n",
    "\n",
    "print(f'REVIEW:\\n {decoded_review}\\n')\n",
    "print(f'Encoded sequence of words:\\n {train_data[ind]}\\n')\n",
    "print(f'Label: {label}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c52eeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews: 12500\n",
      "Number of negative reviews: 12500\n",
      "Maximum length of the positive reviews: 2494\n",
      "Maximum lengths of the negative reviews: 1571\n"
     ]
    }
   ],
   "source": [
    "# split dataset into positive and negative review ones\n",
    "train_data_pos = train_data[train_labels==1]\n",
    "train_data_neg = train_data[train_labels==0]\n",
    "seqlen_train_pos = [len(sequence) for sequence in train_data_pos]\n",
    "seqlen_train_neg = [len(sequence) for sequence in train_data_neg]\n",
    "print(f'Number of positive reviews: {len(train_data_pos)}')\n",
    "print(f'Number of negative reviews: {len(train_data_neg)}')\n",
    "print(f'Maximum length of the positive reviews: {max(seqlen_train_pos)}')\n",
    "print(f'Maximum lengths of the negative reviews: {max(seqlen_train_neg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ff18009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3019537, 1)\n",
      "(2948304, 1)\n"
     ]
    }
   ],
   "source": [
    "# create training matrices\n",
    "X_train_pos = np.concatenate(train_data_pos).reshape(-1,1)\n",
    "X_train_neg = np.concatenate(train_data_neg).reshape(-1,1)\n",
    "print(X_train_pos.shape)\n",
    "print(X_train_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2220d80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialHMM(n_components=7,\n",
       "               random_state=RandomState(MT19937) at 0x7F92DC30F340)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialHMM</label><div class=\"sk-toggleable__content\"><pre>MultinomialHMM(n_components=7,\n",
       "               random_state=RandomState(MT19937) at 0x7F92DC30F340)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialHMM(n_components=7,\n",
       "               random_state=RandomState(MT19937) at 0x7F92DC30F340)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build HMMs, one for each category\n",
    "hmm_pos = hmm.MultinomialHMM(\n",
    "    n_components=7,\n",
    "    n_iter=10)\n",
    "hmm_neg = hmm.MultinomialHMM(\n",
    "    n_components=7,\n",
    "    n_iter=10)\n",
    "\n",
    "# train HMMs (it may take a while)\n",
    "hmm_pos.fit(X_train_pos, seqlen_train_pos)\n",
    "hmm_neg.fit(X_train_neg, seqlen_train_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a51af5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in the test set: 0.81644\n",
      "Precision in the test set (class 0): 0.847004123168699\n",
      "Recall in the test set (class 0): 0.7724\n",
      "F1 score in the test set (class 0): 0.8079835976400686\n",
      "Precision in the test set (class 1): 0.7908242041026395\n",
      "Recall in the test set (class 1): 0.86048\n",
      "F1 score in the test set (class 1): 0.8241829814949618\n"
     ]
    }
   ],
   "source": [
    "# score each test sample, that is, calculate P(O|model)\n",
    "(true_pos, true_neg, false_pos, false_neg) = (0, 0, 0, 0)\n",
    "for x, l in zip(test_data, test_labels):\n",
    "    score_pos = hmm_pos.score(np.asarray(x).reshape(-1,1))\n",
    "    score_neg = hmm_neg.score(np.asarray(x).reshape(-1,1))\n",
    "    if l == 1:\n",
    "        if score_pos > score_neg:\n",
    "            true_pos += 1\n",
    "        else:\n",
    "            false_neg += 1\n",
    "    else:\n",
    "        if score_pos > score_neg:\n",
    "            false_pos += 1\n",
    "        else:\n",
    "            true_neg += 1\n",
    "\n",
    "# number of samples\n",
    "nsamples_all = len(test_data)\n",
    "nsamples_pos = len(test_data[test_labels==1])\n",
    "nsamples_neg = len(test_data[test_labels==0])\n",
    "\n",
    "# calculate accuracy, precision, recall and F1\n",
    "acc = (true_pos + true_neg) / nsamples_all\n",
    "pre_class0 = true_pos / (true_pos + false_pos)\n",
    "pre_class1 = true_neg / (true_neg + false_neg)\n",
    "rec_class0 = true_pos / (true_pos + false_neg)\n",
    "rec_class1 = true_neg / (true_neg + false_pos)\n",
    "f1_score_class0 = 2.0 * pre_class0 * rec_class0 / (pre_class0 + rec_class0)\n",
    "f1_score_class1 = 2.0 * pre_class1 * rec_class1 / (pre_class1 + rec_class1)\n",
    "\n",
    "print(f'Accuracy in the test set: {acc}')\n",
    "print(f'Precision in the test set (class 0): {pre_class0}')\n",
    "print(f'Recall in the test set (class 0): {rec_class0}')\n",
    "print(f'F1 score in the test set (class 0): {f1_score_class0}')\n",
    "print(f'Precision in the test set (class 1): {pre_class1}')\n",
    "print(f'Recall in the test set (class 1): {rec_class1}')\n",
    "print(f'F1 score in the test set (class 1): {f1_score_class1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7214e58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82     12500\n",
      "           1       0.85      0.77      0.81     12500\n",
      "\n",
      "    accuracy                           0.82     25000\n",
      "   macro avg       0.82      0.82      0.82     25000\n",
      "weighted avg       0.82      0.82      0.82     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# eval model using Scikit-learn\n",
    "# score each test sample, that is, calculate P(O|model)\n",
    "y_test = np.asarray(test_labels)\n",
    "y_pred = np.zeros(y_test.shape)\n",
    "for i, x in enumerate(test_data):\n",
    "    score_pos = hmm_pos.score(np.asarray(x).reshape(-1,1))\n",
    "    score_neg = hmm_neg.score(np.asarray(x).reshape(-1,1))\n",
    "    if score_pos > score_neg:\n",
    "        y_pred[i] = 1.0\n",
    "    else:\n",
    "        y_pred[i] = 0.0\n",
    "        \n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d62a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
