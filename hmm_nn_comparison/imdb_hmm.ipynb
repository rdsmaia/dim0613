{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4050c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 06:50:33.591148: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-30 06:50:33.591182: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f678d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6200d422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum word index: 9999\n",
      "Minimum word index: 1\n",
      "Maximum seq length: 2494\n",
      "Minimum seq length: 11\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum of all max indexes\n",
    "max_word_index = max([max(sequence) for sequence in train_data])\n",
    "min_word_index = min([min(sequence) for sequence in train_data])\n",
    "max_seq_len = max([len(sequence) for sequence in train_data])\n",
    "min_seq_len = min([len(sequence) for sequence in train_data])\n",
    "print(f'Maximum word index: {max_word_index}')\n",
    "print(f'Minimum word index: {min_word_index}')\n",
    "print(f'Maximum seq length: {max_seq_len}')\n",
    "print(f'Minimum seq length: {min_seq_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47cedd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW:\n",
      " ? this movie is so bad it's comical in fact mystery science theatre 3000 the television show in which three characters watch and parody bad movies used this very film to mock i suggest watching it maybe on youtube instead of actually seeing this movie br br please do not see hobgoblins if you're not prepared to stop within the first scene actually do not see this movie period please at least not seriously its jokes are not funny to say the least and you'll have much more fun ? or watching a parody of it then viewing the movie br br you may feel yourself becoming sick upon watching so spare yourself read a book do the ? anything is more fun than watching hobgoblins\n",
      "\n",
      "Encoded sequence of words:\n",
      " [1, 14, 20, 9, 38, 78, 45, 2849, 11, 192, 736, 1067, 1716, 5083, 4, 699, 123, 11, 63, 289, 105, 106, 5, 2111, 78, 102, 343, 14, 55, 22, 8, 7259, 13, 1467, 149, 12, 279, 23, 6221, 305, 7, 165, 319, 14, 20, 10, 10, 591, 81, 24, 67, 8029, 48, 335, 24, 2848, 8, 570, 746, 4, 86, 136, 165, 81, 24, 67, 14, 20, 810, 591, 33, 222, 24, 615, 94, 640, 26, 24, 163, 8, 135, 4, 222, 5, 490, 28, 76, 53, 253, 2, 42, 149, 6, 2111, 7, 12, 95, 829, 4, 20, 10, 10, 25, 203, 235, 624, 1575, 1195, 725, 149, 38, 4062, 624, 332, 6, 274, 81, 4, 2, 233, 9, 53, 253, 74, 149, 8029]\n",
      "\n",
      "Label: negative review\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# step 1: get an index randomly\n",
    "ind = random.randint(0,25000)\n",
    "\n",
    "# step 2: reverse word index to map integer indexes to their respective words\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# Step 3: decode the review, mapping integer indices to words\n",
    "#\n",
    "# indices are off by 3 because 0, 1, and 2 are reserverd indices for \"padding\", \"Start of sequence\" and \"unknown\"\n",
    "decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[ind]])\n",
    "label = 'positive review' if train_labels[ind] == 1 else 'negative review'\n",
    "\n",
    "print(f'REVIEW:\\n {decoded_review}\\n')\n",
    "print(f'Encoded sequence of words:\\n {train_data[ind]}\\n')\n",
    "print(f'Label: {label}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c52eeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "# split dataset into positive and negative review ones\n",
    "train_data_pos = train_data[train_labels==1]\n",
    "train_data_neg = train_data[train_labels==0]\n",
    "print(len(train_data_pos))\n",
    "print(len(train_data_neg))\n",
    "seqlen_train_pos = [len(sequence) for sequence in train_data_pos]\n",
    "seqlen_train_neg = [len(sequence) for sequence in train_data_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ff18009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3019537, 1)\n",
      "(2948304, 1)\n"
     ]
    }
   ],
   "source": [
    "# create training matrices\n",
    "X_train_pos = np.concatenate(train_data_pos).reshape(-1,1)\n",
    "X_train_neg = np.concatenate(train_data_neg).reshape(-1,1)\n",
    "print(X_train_pos.shape)\n",
    "print(X_train_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2220d80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianHMM(covariance_type=&#x27;tied&#x27;, n_components=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianHMM</label><div class=\"sk-toggleable__content\"><pre>GaussianHMM(covariance_type=&#x27;tied&#x27;, n_components=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianHMM(covariance_type='tied', n_components=7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build HMMs, one for each category\n",
    "hmm_pos = hmm.GaussianHMM(n_components=7, covariance_type=\"tied\", n_iter=10)\n",
    "hmm_neg = hmm.GaussianHMM(n_components=7, covariance_type=\"tied\", n_iter=10)\n",
    "\n",
    "# train HMMs (it may take while)\n",
    "hmm_pos.fit(X_train_pos, seqlen_train_pos)\n",
    "hmm_neg.fit(X_train_neg, seqlen_train_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a51af5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in the test set: 0.53516\n",
      "Precision in the test set: 0.5464048146974976\n",
      "Recall in the test set: 0.414\n",
      "F1 score in the test set: 0.4710755086250057\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy, precision, recall and F1\n",
    "true_pos = 0\n",
    "true_neg = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "for x,l in zip(test_data, test_labels):\n",
    "    score_pos = hmm_pos.score(np.asarray(x).reshape(-1,1))\n",
    "    score_neg = hmm_neg.score(np.asarray(x).reshape(-1,1))\n",
    "    if l == 1:\n",
    "        if score_pos > score_neg:\n",
    "            true_pos += 1\n",
    "        else:\n",
    "            false_neg += 1\n",
    "    else:\n",
    "        if score_pos > score_neg:\n",
    "            false_pos += 1\n",
    "        else:\n",
    "            true_neg += 1\n",
    "\n",
    "nsamples = len(test_data)\n",
    "nsamples_pos = len(test_data[test_labels==1])\n",
    "nsamples_neg = len(test_data[test_labels==0])\n",
    "\n",
    "acc = (true_pos + true_neg) / nsamples\n",
    "pre = true_pos / (true_pos + false_pos)\n",
    "rec = true_pos / (true_pos + false_neg)\n",
    "f1_score = 2.0 * pre*rec/(pre + rec)\n",
    "\n",
    "print(f'Accuracy in the test set: {acc}')\n",
    "print(f'Precision in the test set: {pre}')\n",
    "print(f'Recall in the test set: {rec}')\n",
    "print(f'F1 score in the test set: {f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be8ac92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
